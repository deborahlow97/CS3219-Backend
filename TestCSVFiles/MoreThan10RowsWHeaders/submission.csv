#,track #,track name,title,authors,submitted,last updated,form fields,keywords,decision,notified,reviews sent,abstract
2,3,Posters and Demos,"Quantitative Approach for Coffee Rust, Production and Futures",Laxxx Kaxx,2017-12-12 13:53,2017-12-12 13:53,,"Data mining
Econometrics
commodity futures
coffee trading
statistical analysis
hemileia vastatrix",reject,yes,yes,"More than two billion cups of coffee are consumed worldwide each day [14]. The livelihood of 120 million people depends on the coffee supply chain [33]. Coffee rust leads to production losses of over $500 million worldwide and may affect futures prices [15]. Coffee rust is caused by the coffee berry borer, or Hemileia vastatrix fungus, at temperatures from 10-30 C, and is one of the main diseases that attacks the coffee arábica plant [19]. Coffee is the second largest traded commodity worldwide, with about $100 billion in volume traded annually [32, 4]. Understanding the relationship between coffee rust, production quantities and futures prices is important to anyone affected by the coffee supply chain. This research offers a new quantitative approach for describing and visualizing the relationship between coffee rust, amount of coffee produced and futures prices."
3,3,Posters and Demos,Digital library System in Intelligent Infrastructure for Human-Centered Communities,Yx Shxx,2017-12-20 21:09,2017-12-20 23:00,,"complex adaptive system
data infrastructure
digital libraries
intelligent infrastructure
human-centered communities
infrastructure data
smart digital library",reject,yes,yes,"This poster presents a socio-technical research on the strategic development of a large-scale transdisciplinary area, named Intelligent Infrastructure for Human Centered Communities, in the organizational context of Virginia Tech. Within such development, this study explored the future vision and projective scenarios of data infrastructure and digital libraries for smart community development. It further discusses the next generation data and information user experience, smart infrastructure data environment, and future library capabilities."
4,1,Full Papers,The Rhetorical Context of Citations in Scholarly Big Data,"Mubxxxxx Imxxx,Saexxxxx Haxxxx,Sehxxxx Iqxxxx,Naxx Aljxxxxx and Axx Dxx",2017-12-25 18:51,2018-01-18 17:26,,"Machine learning
Citation context analysis
Deep learning
influential citations",reject,yes,yes,"Information retrieval systems for scholarly literature rely heavily not only on text matching but on semantic and context-based features. Readers nowadays are most interested in how important an article is, its purpose and how influential it is for follow-up research work? Numerous techniques that tap the power of machine learning and artificial intelligence have been developed to improve the retrieval of the most influential scientific literature. We compare and improve on four existing state-of-the-art techniques designed to identify influential citations. Our approach supports information retrieval algorithms that detect and fetch scientific articles on the basis of both qualitative and quantitative indices in scholarly big data. We consider 450 citations from the corpus of 20,527 papers available from the Association for Computational Linguistics, classified by experts as either important or unimportant, and extract 64 features based on the methodology of four state-of-the-art techniques. We apply the Extra Trees classifier to select 29 best features and apply Random Forest and Support Vector Machine to all techniques. We find that our supervised classification model improves on the state-of-the-art by 11.25%, with 89% Precision Recall Curve using the Random Forest Classifier. Finally, we present our deep learning model, the Long Short-Term Memory network, that uses all 64 features to distinguish important and unimportant citations with 92.57% accuracy."
5,1,Full Papers,"Challenges & Solutions to Deploying Cloud Services in Libraries:  Data Issues Influencing IT, People, Costs, and Policy Challenges","Devxxxxx Poxxxx,Reyxxxx Regensxxxxxxxxxxx and Dwxxxx Huxxx",2017-12-28 03:20,2017-12-28 03:20,,"Libraries
Cloud services
SaaS
Integrated library systems
Project management",reject,yes,yes,"This paper analyzes challenges to deploying cloud services in different types of libraries and proposes a set of precautions libraries need to take when planning, deploying, and maintaining cloud services. We apply grounded theory principles to analyze 75 articles authored by library administrators, librarians with IT expertise, IT professionals, cybersecurity experts, and business consultants engaged in planning, deploying, and maintaining cloud services in libraries. Data analysis reveals that a majority of the past literature reports challenges to implementing Software a Service (SaaS) in libraries. The seven key areas critical to the successful implementation of SaaS in libraries are related to: (1) data, (2) authentication and privacy of patrons, (3) skills and knowledge of library staff and organizational culture, (4) IT infrastructure, (5) features of cloud services, (6) fixed and operational costs associated with data and technology, and (7) policies and contracts. Data issues like access, storage, ownership, curation, security, confidentiality, loss, migration, and redundancy seem to have the most influence on SaaS deployment in libraries. Based on project management principles, we make seven recommendations to manage the challenges identified in this study. Libraries can learn and benefit from study findings in terms of reducing their reliance on external IT consultants and managing their scarce resources for better serving patrons."
6,2,Short Papers,The Navigation of Topic Space,Jxx Haxx,2017-12-30 19:48,2018-01-12 11:45,,"collection navigation
classification
browsing",reject,yes,yes,"This paper reports on the development and evaluation of the topic space recommendation model, proposed here as an alternative to the personalization algorithms based on large datasets that often result in content and subject matter filter bubbles. The content filter bubbles that dominate contemporary Internet media platforms have been shown to provide users more of what they already consume and exclude relevant content at the expense of user exploration and discovery."
7,1,Full Papers,How it Happened:  Discovering and Archiving the Evolution of a Story Using Social Signals,"Omxx Alxxxx,Vasxxxx K and ylxxx",2018-01-02 18:35,2018-01-02 18:35,,"Social pseudo relevance feedback
social query expansion
social data
event evolution
archiving",accept,yes,yes,"Social networks like Twitter and Facebook are the largest sources of public opinion and real-time information on the Internet.  If an event is of general interest, news articles follow and eventually a Wikipedia page. We propose the problem of automatic event story  generation by combining  social and news data to construct a new type of document in the form of a Wiki-like page structure. We introduce  a technique that shows the evolution of a story as perceived by the crowd in social media, along with editorially authored articles annotated with examples of social media as supporting evidence. At the core of our research, is  the temporally sensitive extraction of data that serve as context for retrieval purposes.
Our approach includes a fine-grained vote counting strategy that is used for weighting purposes,  pseudo relevance feedback and query expansion with social data and web query logs along with a timeline algorithm as the base for a 
story.
We demonstrate the effectiveness of our approach by processing a dataset comprising millions of English language tweets generated over a one year period and present a full implementation of our system.
"
8,2,Short Papers,Methodological Considerations in Developing Cultural Heritage Digital Libraries: A Community-driven Framework,Axx Shxxx,2018-01-04 20:36,2018-01-04 20:36,,"Digital libraries
Community archives
Community-driven methodologies
Inuit communities
Canada",reject,yes,yes,"There is a growing interest in the development of community digital libraries and archives that focus on cultural heritage preservation and access, particularly in the context of indigenous and aboriginal communities. We present a multi-disciplinary methodological framework that was developed to create the Digital Library North for Inuit communities in Canada’s north. The framework adopts a holistic approach, taking into account existing physical and digital collections, information search behaviour of community members, culturally appropriate metadata, user interface design, usability evaluation and sustainability. The methodological framework provides an empirically-supported model for developing community-focused digital libraries and archives that focus on cultural heritage preservation and access."
9,2,Short Papers,An adaptive document recognition system for lettrines,"Nxx Vxx,Micxxxxx Couxxxxx and Jeaxxxxxx Ogxx",2018-01-05 12:00,2018-01-05 12:00,,"Drop caps
Indexing
Relevance feedback
Human-centered",reject,yes,yes,"In this paper, we propose an approach to interactively propagate the historians’ knowledge to a database of lettrines images manually populated by historians with annotations. Based on a novel document indexing processing scheme which combines the use of the Zipf law and the use of bag of patterns, our approach extends the Bag of Words model to represent the knowledge by visual features through relevance feedback. Then annotation propagation is automatically performed to propagate knowledge to the lettrines database. Our approach is presented together with preliminary experimental results and an illustrative example."
10,1,Full Papers,Putting Dates on the Map: Harvesting and Analyzing Street Names with Date Mentions and their Explanations,"Jaxxxx Strxxxxxx,Roxxxx Andxxxx and Dhxxx Guxx",2018-01-09 10:11,2018-01-12 15:46,,"digital humanities
street name analysis
temporal tagging
explanation harvesting",accept,yes,yes,"Street names are not only used across the world as part of addresses, but also reveal a lot about a country’s identity. Thus, they are subject to analysis in the fields of geography and social science. There, typically, a manual analysis limited to a small region is performed, e.g., focusing on the renaming of streets in a city after a political change in a country. Surprisingly, there have been hardly any automatic, large-scale studies of street names so far, although this might lead to interesting insights regarding the distribution of particular street name phenomena.
In this paper, we present an automated, world-wide analysis of a specific type of street names: street names with date references. Such temporal streets are frequently used to commemorate important events and thus particularly interesting to study. After applying a multilingual temporal tagger to discover such street names, we analyze their temporal and geographic distributions on different levels of granularity. Furthermore, we present an approach to automatically harvest potential explanations why streets in specific regions refer to particular dates. Despite the challenges of the tasks, our evaluation demonstrates the feasibility of both, the temporal street extraction and the explanation harvesting approaches."
12,1,Full Papers,An Experimental Analysis on the Quality of Word Embedding Models Trained on n-Gram Data,"Abxx Elxxxx,Adxxxx Engxxxxxx,Maxxxx Schxxxxx and Klexxxx Bأxx",2018-01-10 19:30,2018-01-10 19:30,,"Experimental analysis
N-grams
Word embedding models",reject,yes,yes,"Word embeddings are powerful tools that facilitate better search and data analysis on large-scale digital libraries. They consider the semantics of words extracted from an arbitrary text corpus, such as the Wikipedia dump. Embedding models reflect how the respective language is used in the training corpus. To this end, various approaches use the Google n-gram corpus. It is the largest currently available corpus (with historic data) on the web and exists for several languages. Hence, it is one of the most important publicly available textual digital library on the web. n-gram corpora are an aggregated representation which can even be published if the underlying full text is subject to copyright protection. 
However, n-gram corpora only offer a small window into the full text -- 5 words for the Google corpus at best. This gives way to the concern whether the extracted word semantics are of high quality. The question we study is which quality differences compared to word embedding models computed on full-text corpora one can expect. We answer this question by means of systematic experiments. Our findings confirm that one generally can expect high quality for n-grams with n > 2 and a corpus size dependent value of the minimum count parameter. We also make all models trained with different parameter combinations publicly available on our website; this currently is one of the largest collection of embedding models openly accessible."
13,1,Full Papers,Entity name extraction from faculty directories,Joxxx Maxxxx and Berxxxxx Ribexxxxxxxx,2018-01-10 20:02,2018-01-10 20:02,,"Information extraction
Web data extraction
Statistical classifier",reject,yes,yes,"Reliable researcher affiliation data is necessary to allow enquiring about international research group productivity and publication patterns. Public bibliographic databases such as DBLP and Google Scholar hold invaluable data about the academic environment. However, the researcher affiliation information is frequently missing or outdated. We propose a statistical data extraction method to
acquire affiliation information directly from university websites and solve the name extraction task in general. Previous approaches to web data extraction either lack in flexibility, because wrappers do not generalize well on cross website tasks, or they lack in precision, because domain agnostic methods neglect useful properties of this particular application domain. Our statistical approach solves
the name extraction task with a framework that incorporates both textual and structural features to yield an outstanding tradeoff between generality and precision. We conducted experiments over a collection of 152 faculty web pages in multiple languages from universities in 49 countries and obtained 94.40% precision, 97.61% recall and 0.9597 F-measure at the extraction task."
14,3,Posters and Demos,Finding New Donors,Kexxxx Rexx and Suxxx V,2018-01-10 20:11,2018-01-10 20:11,,"Archives
Digitization
Fundraising
Preservation
Research and Statistics
Special Collections",reject,yes,yes,"The USF Foundation’s Prospect Research Library is digitizing donor files and important historical documents for preservation and to expand access for USF Foundation staff. The donor files will be used for sociological research to determine common characteristics of donors, factors that help target new and potential donors, and more effective ways of reaching out to the community and existing donor base. The poster presentation will highlight the purpose of the digitization project as well as the organization and curation of the digital library. SobekCM, a cultural heritage platform, is being used to create the digital library of historical materials and was chosen because of the highly customizable design. The SobekCM customizations and the overall organization of the digital library will be discussed as a part of the presentation. "
15,2,Short Papers,BSOnto: A Binary Similarity Calculation Method on Ontology Fusion in Knowledge bases,Wxx Lxx and Hxx Waxx,2018-01-11 09:05,2018-01-11 09:05,,"Heterogeneous ontology
Ontology fusion
Ontology merging
Semantic similarity
Heterogeneous data
Digital library",reject,yes,yes,"Many methods on ontology fusion based on massive semantic similarity calculation have been developed while hardly united. This paper contributes a method for ontology fusion based on the inspiration of binary metrics (BSOnto), with the aim to reduce the massive similarity calculation both spatially and logically. By introducing the definition of heterogeneous ontology, entities of ontologies, and rules of ontology fusion on the base of concept fusion and relationship fusion, we put forward the algorithm of main traverse procedure. To testify the usability of our proposal, we conduct two experiments with standard ontologies. The experiment with small datasets of ontologies describes that BSOnto has a higher precision and a lower recall than some tools, and the F-measure is approximately above 0.8. The experiment with large dataset affirms the high precision and F-measure, and timeless efficiency. BSOnto will be improved on stability for large data."
16,1,Full Papers,Keep it Simple: Effective Unsupervised Author Disambiguation with Relative Frequencies,Toxxxx Baxxxx,2018-01-11 16:29,2018-01-11 16:29,,"Author Name Disambiguation
Probabilistic Similarity
Agglomerative Clustering
Trivial Baseline",accept,yes,yes,"This work addresses the problem of author name homonymy in the Web of Science.
Aiming for an efficient, simple and straightforward solution, we introduce a novel probabilistic similarity measure for author name disambiguation based on feature overlap.
Using the researcher-ID available for a subset of the documents in the Web of Science, we evaluate the application 
of this measure in the context of agglomeratively clustering author mentions.
We focus on a concise evaluation that shows clearly for which problem setups and at which time during the clustering process our approach works best.
In contrast to most other works in this field, we are skeptical towards the performance of author name disambiguation methods in general and compare our approach to the trivial single-cluster baseline.
Our results are presented separately for each correct clustering size as we can explain that, when treating all cases together, the trivial baseline and more sophisticated approaches are hardly distinguishable in terms of evaluation results.
Our model shows state-of-the-art performance for all correct clustering sizes without any discriminative training and with tuning only one convergence parameter."
17,1,Full Papers,Evaluation of Conformance Checkers for Long-Term Preservation of Multimedia Documents,"Nixxxx Fexxx,Giaxxxxxx Silxxxxx,Erxx Bruxxxxx,Boxxx Douxxxx,Antxxxxxx Frxxx,Maxxxx Gexxx,Klxx Jadxxxxxx,Boجxxxx Jusxxxxx,Bexx Lemxxxx,Jerxxxxx Marxxxxx,Viجxxxxx Munxxxx,Soجxxxx Olixxxxx,Claxxxx Praxxxxx,Daxx Rixx,Stxxxx Rohdxxxxxxxx,Xaxx Tarxxxxx,Erxxx Verxxxxxxx,Benxxxxx Youxxxx and Caxx Wixxx",2018-01-11 16:38,2018-01-11 16:38,,"long-term preservation
conformance checking
evaluation",accept,yes,yes,"We develop an evaluation framework for the validation of conformance checkers for the long-term preservation. The framework assesses the correctness, usability, and usefulness of the tools for three media types: PDF/A (text), TIFF (image), and Matroska (audio/video). Finally, we report the results of the validation of these conformance checkers using the proposed framework."
18,1,Full Papers,Detecting Reliable Novel Word Senses: A Network-Centric Approach,"Abxxx Jaxx,Anixxxx Mukxxxxxx and Paxxx Goxx",2018-01-12 11:11,2018-01-12 11:11,,"Novel Sense Detection
Distributional Thesaurus Network
Complex Network Measures",reject,yes,yes,"In this era of Big Data, due to expeditious exchange of information on the web, words are being used to denote newer meanings, causing linguistic shift. With the recent availability of large  amounts of  digitized texts, an automated analysis of the evolution of language has become possible. 
Our study mainly focuses on improving the detection of new word senses. This paper presents a unique proposal based on network features to improve the precision of new word sense detection. For a candidate word where a new sense (birth) has been detected by comparing the sense clusters induced at two different time points, we further compare the network properties of the subgraphs induced from novel sense cluster across these two time points. Using the mean fractional change in edge density, structural similarity and average path length as features in an SVM classifier, manual evaluation gives precision values of 0.86 and 0.74 for the task of new sense detection, when tested on 2 distinct time-point pairs, in comparison to the precision values in the range of 0.23-0.32, when the proposed scheme is not used. The outlined method can therefore be used as a new post-hoc step to improve the precision of novel word sense detection in a robust and reliable way where the underlying framework uses a graph structure. Another important observation is that even though our proposal is a post-hoc step, it can be used in isolation and that itself results in a very decent performance achieving a precision of 0.54-0.62. Finally, we show that our method is able to detect the well-known historical shifts in 80% cases."
20,8,JCDL 2018 - Workshops,Workshop Proposal on Knowledge Discovery from Digital Libraries,"Hxx Sxx,Wx Hx and  xx",2018-01-13 00:18,2018-01-13 00:18,,"Workshop proposal
Knowledge Discovery
Digital Libraries",accept,yes,yes,"Knowledge is defined as facts, information, descriptions or skills acquired through experience or education. Valid, useful knowledge can help people make better predictions, support decision making and improve people’s lives. Knowledge Discovery focuses on searching and extracting useful knowledge from data, databases and documents with different methodologies. The goal of Knowledge Discovery is mainly to uncover hidden relationships between data with techniques from artificial intelligence, mathematics, statistics, and algorithms.  
A digital library stores and organizes a collection of digital objects, such as text, images, videos, sounds. Some of the characteristics that digital library has can make knowledge discovery easier: 1) digital library is an open platform. Users from all over the world can have access to the collection of digital library via internet; 2) digital library is an integration of a variety of information and multimedia services which allows multiple access; 3) digital library can provide fast and efficient access and user friendly interfaces for users to retrieve information; 4) digital library usually is a large, well organized collection that persist over time. It can contain many formats and digital objects that may be otherwise unobtainable. All the above characteristics of digital library will facilitate knowledge extraction, transformation, analyzing and presentation. 
The objectives of the proposed workshop are to explore:
1) Existing and novel techniques to extract and present knowledge from Digital Libraries
2) Advanced ways to organize and maintain Digital Libraries to facilitate Knowledge Discovery
3) Knowledge Discovery applications in Business
4) New challenges and technologies have been brought to the area of knowledge Discovery and Digital Libraries"
21,1,Full Papers,Innovation and Revenue: Deep Diving into the Temporal Rank-shifts of Fortune 500 Companies,"Maxxxx Sixxx,Arixxxx Pxx,Lixxxx Dxx and Anixxxx Mukxxxxx",2018-01-13 06:19,2018-01-13 06:19,,"Patent Citations
Fortune 500 Companies
Innovation
Revenue",reject,yes,yes,"Research and innovation is an important agenda for any company to remain competitive in the market. The relationship between innovation and revenue is a key metric for companies to decide on the amount to be invested for future research. Two important parameters to evaluate research outputs are the quantity and quality of scientific papers and patents. Our work studies the relationship between innovation and revenue generation for several Fortune 500 companies over a period of time. 
We perform a comprehensive study of the patent citation dataset available in the Reed Technology Index collected from the US Patent Office. We observe several interesting relations between parameters like number of (i) patent applications, (ii) patent grants, (iii) patent citations and Fortune 500 ranks of companies. We also study the trends of these parameters varying over the years and derive causal explanations for these with qualitative and intuitive reasoning. As an additional objective, we also discuss two interesting use cases of industry giants illustrating fierce technology competition and its effect on overall ranks. To facilitate reproducible research, we shall soon make all the codes and the processed dataset available in the public domain."
22,1,Full Papers,Investigating User Trust in Online Health Rumors based on Rumor Presentation,Shexxxx Dexx and Shaxxxxxx Fx,2018-01-14 00:02,2018-01-14 00:02,,"Trust
Health rumor
Health information need
Patient information
Tnormtion seeking behavior",reject,yes,yes,"Due to the increasing availability of online information, online rumors have become prevalent nowadays. Thus, it is not astonishing that online search engines may return unverified rumors on health-related matters. However, false health information may result in serious consequences if users trust the information. Hence, an understanding of the characteristics of online health rumors that people trust is important for fighting their spread. Based on real online health rumor data collected from a Chinese database, this study investigates the predictors of user trust in online health rumors. Surveys and user interviews were conducted to study how users evaluate different types of rumors about health. We found that the use of pictures has an insignificant influence on user trust in an online health rumor, and significant impact was observed for verification and hyperlinks. This paper provides an effective instrument for predicting the strength of online rumors about health. "
23,2,Short Papers,Semantic Modeling with Foundries,Roxxxx Alxxx and Yooxxxxx Kxx,2018-01-14 01:10,2018-01-18 14:30,,"Cultural Heritage Foundry
Entity Transitions
Descriptive Programs
Direct Representation
XFO",reject,yes,yes,"We analyze challenges for the development of the Human Activities and Infrastructures Foundry.  We explore a rich semantic modeling approach to describe two Korean ceramic water droppers used to mix ink for calligraphy, how they were produced and the reasons for their differing aesthetic.  Our modeling supports schema — like Thick Objects – and allows for transitions of Entities based on the relationships to other Entities with which they are associated.  We explore the similarity of our approach to object-oriented analysis and modeling."
24,8,JCDL 2018 - Workshops,"JCDL 2018 Workshop Proposal - Image Collections: Creation, Organization, Access, and Use","Wxx Lx,Jexxx Wexx,Brxxx Oâ€xxxxxxx,Kryxxxxx Matxxxxx,Qinxxxx Zxx,Jaxxx Lx and Jiaxxxxxx Cxx",2018-01-14 13:10,2018-01-14 13:10,,"Image collections
Image annotation
Image and video retrieval
Image organization
Image seeking and use
Visual image metrics",accept,yes,yes,"We propose to have a full day workshop at JCDL 2018. This workshop will provide an opportunity for participants to exchange research ideas on image collections, including the creation, organization, access and use (COAU) of various image datasets. We expect to discuss various theories, methods, techniques, challenges, and new research directions as related to image’s COAU. Especially we would like to explore innovative ideas on image annotation, retrieval, use behavior & personas, processing of different types of images, and visual image metrics. The workshop will allow researchers to communicate with their peers on projects and develop new ideas through presentation and discussion. We hope to establish a community of researchers from related disciplines and explore questions critical to the future development of image’s COAU. Participants of this workshop will be invited to submit a full paper to a special issue at The Electronic Library (http://www.emeraldinsight.com/journal/el) on Image Collections."
25,1,Full Papers,A Visualization Scheme for Multi-Entity Relationship,"Pexx Zhxx,Yinxxxxx Zxx,Jixxxx Yx,Yxx Zhxxx and Jiaxxxxx W",2018-01-14 13:25,2018-01-15 04:32,,"data visualization
data model
visualization scheme
Chinese herbal medicine",reject,yes,yes,"In the era of big data, huge amounts of data are generated. There are various entities among these data. If we can visualize the relationship among these entities, it will be very helpful for understanding the data itself. In the process of mining the relationship among data entities, we find that there are some similarity in these entity relationships. On this basis, this paper proposes an entity relationship model, and presents a set of visualization schemes that can display the relationship of multi entities. The scheme is applied to the visualization of Chinese herbal medicine prescription dataset and paper dataset, which accord with the model. The result is very satisfying, and proves the good applicability of the scheme."
26,2,Short Papers,Building a Theoretical Framework for the Development of Digital Scholarship Services in China’s Universities,"Lixxxx Zhxx,Xixxx Lx and Txx Zijxxxx",2018-01-14 14:48,2018-01-14 14:48,,"Digital scholarship
Digital scholarship services
Theoretical framework
University libraries",accept,yes,yes,"The provision of digital scholarship services (DSS) in China’s university is very unsystematic and fragmented. This paper reports on a literature review that aims to develop a comprehensive theoretical framework, which can serve as a practical guide for the development of DSS in China’s university libraries. The framework was developed through systematically searching, screening, assessing, coding and aggregating DSS as reported in the existing body of literature. Academic literature, both in Chinese and English, as well as relevant professional reports are carefully searched, selected and analysed. The analysis of the literature pointed to 25 DSS in six categories: supporting services, formulating research ideas, locating research partners, proposal writing, research process, and publication. This paper focuses on the development of DSS in China’s university libraries, but the research findings and the framework developed can provide useful insights and indications that can be shared across international borders."
27,1,Full Papers,My Approach = Your Apparatus? Entropy-Based Topic Modeling on Multiple Domain-Specific Text Collections,Juxxxx Rixxx and Raxx Krexxxx,2018-01-14 16:29,2018-01-17 15:40,,"Topic modeling
Automatic domain term extraction
Entropy",accept,yes,yes,"Comparative text mining extends from genre analysis and political bias detection to the revelation of cultural and geographic differences, through to the search for prior art across patents and scientific papers. These applications use cross-collection topic modeling for the exploration, clustering, and comparison of large sets of documents, such as digital libraries. However, topic modeling on documents from different collections is challenging because of domain-specific vocabulary. We present a cross-collection topic model combined with automatic domain term extraction and phrase segmentation. This model distinguishes collection-specific and collection-independent words based on information entropy and reveals commonalities and differences of multiple text collections. We evaluate our model on patents, scientific papers, newspaper articles, forum posts, and Wikipedia articles. In comparison to state-of-the-art cross-collection topic modeling, our model achieves up to 13% higher topic coherence, up to 4% better perplexity, and up to 31% higher document classification accuracy. More importantly, our approach is the first topic model that ensures disjunct general and specific word distributions, resulting in clear-cut topic representations."
28,1,Full Papers,Toward Sentiment Sensitive Ranking of Scientific Papers,Souxxxx Ghxxx and Chxxxx Shxx,2018-01-14 18:13,2018-01-14 18:13,,"Bibliometrics
Scientometrics
Bibliometric Information Retrieval
Citation Networks
Citation Sentiment Analysis
Ranking
Recommendation",reject,yes,yes,"In this paper, we highlight the importance of considering sentiment of citation while preparing ranking indexes for scientific literature. Sentiment analysis has proven to be a popular research area for analyzing social media texts, newspaper articles, and product reviews. However, for scientific papers, it is often assumed that the sentiment associated with citation instances is inherently positive. This assumption is due to the hedged nature of sentiment in citations, which is difficult to identify and classify. As a result, most of the existing indexes focus only on the frequency of citation. In this research, we aim to perform automatic sentiment classification of citation instances. We use the sentiment score in addition to the frequency of citation to build a ranking index for scientific papers. By using various baselines, we highlight the impact of our index on the ACL Anthology collection of papers."
29,1,Full Papers,Using Deep Learning For Title-Based Semantic Subject Indexing To Reach Competitive Performance to Full-Text,"Floxxxx Mxx,Luxxx Gaxxx and Anxxxx Scxxx",2018-01-14 22:31,2018-01-17 18:01,,"text classification
deep learning
digital libraries",accept,yes,yes,"For (semi-)automated subject indexing systems in digital libraries, it is often
more practical to use metadata such as the title of a publication instead of the
full-text or the abstract.
Therefore, it is desirable to have good text mining and text classification algorithms that operate well already on the title of a publication.
So far, the classification performance on titles is not competitive with the
performance on the full-texts if the same number of training samples is used for training. 
However, it is much easier to obtain title data in large quantities and to use
it for training than full-text data.
In this paper, we investigate the question how models
obtained from training on increasing amounts of title training data compare to
models from training on a constant number of full-texts.
We evaluate this question on a large-scale dataset from the medical domain
(PubMed) and from economics (EconBiz).
In these datasets, the titles and annotations of millions
of publications are available, and they outnumber the available full-texts by
a factor of 20 and 15, respectively. To exploit these large amounts of data to
their full potential, we develop three strong deep learning classifiers and
evaluate their performance on the two datasets.
The results are promising. On the EconBiz dataset, all three classifiers
outperform their full-text counterparts by a large margin.
The best title-based classifier outperforms the best full-text method by 9.9%. 
On the PubMed dataset, the best title-based method almost reaches the
performance of the best full-text classifier, with a difference of only 2.9%."